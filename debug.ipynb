{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-13T19:05:32.902147200Z",
     "start_time": "2024-05-13T19:05:32.768627700Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Pytorch is not installed. Go to https://pytorch.org/.\nWe have some installation instructions on our Github page.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "File \u001B[1;32m~\\anaconda3\\envs\\unsloth_env\\lib\\site-packages\\unsloth\\__init__.py:40\u001B[0m\n\u001B[0;32m     39\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 40\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m     41\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'torch'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01munsloth\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m FastLanguageModel\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\unsloth_env\\lib\\site-packages\\unsloth\\__init__.py:42\u001B[0m\n\u001B[0;32m     40\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m     41\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[1;32m---> 42\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPytorch is not installed. Go to https://pytorch.org/.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\\\n\u001B[0;32m     43\u001B[0m                       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWe have some installation instructions on our Github page.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     45\u001B[0m \u001B[38;5;66;03m# We support Pytorch 2\u001B[39;00m\n\u001B[0;32m     46\u001B[0m \u001B[38;5;66;03m# Fixes https://github.com/unslothai/unsloth/issues/38\u001B[39;00m\n\u001B[0;32m     47\u001B[0m torch_version \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39m__version__\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mImportError\u001B[0m: Pytorch is not installed. Go to https://pytorch.org/.\nWe have some installation instructions on our Github page."
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "from unsloth import FastLanguageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FastLanguageModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 6\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01minspect\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\n\u001B[0;32m      5\u001B[0m     inspect\u001B[38;5;241m.\u001B[39mgetsource(\n\u001B[1;32m----> 6\u001B[0m         \u001B[43mFastLanguageModel\u001B[49m\n\u001B[0;32m      7\u001B[0m     )\n\u001B[0;32m      8\u001B[0m )\n",
      "\u001B[1;31mNameError\u001B[0m: name 'FastLanguageModel' is not defined"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "\n",
    "\n",
    "print(\n",
    "    inspect.getsource(\n",
    "        FastLanguageModel\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T19:05:25.117603400Z",
     "start_time": "2024-05-13T19:05:25.085096700Z"
    }
   },
   "id": "64a3ce31b53a07f4"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(\n",
    "    \n",
    "    find_dotenv()\n",
    ")\n",
    "\n",
    "client = Groq(\n",
    "        api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T20:05:23.091255100Z",
     "start_time": "2024-05-13T20:05:22.509045Z"
    }
   },
   "id": "f759c68eb1589511"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# test the LLM"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4becec36489f8981"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models are artificial intelligence (AI) models that are designed to quickly process and generate human-like language, often for real-time applications. Their importance lies in several areas:\n",
      "\n",
      "1. **Conversational AI**: Fast language models power many conversational AI systems, such as virtual assistants, chatbots, and customer service agents. They enable these systems to respond rapidly to user queries, making interactions feel more natural and efficient.\n",
      "2. **Real-time processing**: Fast language models can process and generate text rapidly, making them suitable for applications that require instantaneous responses, such as:\n",
      "\t* Live chat support\n",
      "\t* Real-time translation\n",
      "\t* Sentiment analysis\n",
      "3. **Inferential generation**: Fast language models can generate text quickly, allowing them to infer missing information or complete sentences, which is particularly useful in:\n",
      "\t* Question answering\n",
      "\t* Text summarization\n",
      "\t* Opinion extraction\n",
      "4. **Large-scale text analysis**: Fast language models can quickly process large volumes of text data, enabling tasks like:\n",
      "\t* Sentiment analysis\n",
      "\t* Entity recognition\n",
      "\t* Topic modeling\n",
      "5. **Reduced latency**: Fast language models can reduce latency in applications that require fast processing, such as:\n",
      "\t* Social media sentiment analysis\n",
      "\t* Real-time language translation\n",
      "\t* Speech-to-text systems\n",
      "6. **Improved user experience**: By providing rapid responses, fast language models can enhance the user experience in various applications, such as:\n",
      "\t* Conversational commerce\n",
      "\t* Personalized recommendations\n",
      "\t* Real-time assistance\n",
      "7. **Advancements in NLP**: Fast language models have contributed to the development of more sophisticated Natural Language Processing (NLP) techniques, driving innovation in areas like:\n",
      "\t* Machine translation\n",
      "\t* Text classification\n",
      "\t* Information retrieval\n",
      "8. **Economic benefits**: Fast language models can enable faster and more accurate processing of large text datasets, leading to cost savings and increased efficiency in industries such as:\n",
      "\t* Customer service\n",
      "\t* Marketing\n",
      "\t* Healthcare\n",
      "\n",
      "In summary, fast language models have a significant impact on various aspects of AI, from conversational AI and real-time processing to large-scale text analysis and improved user experience. Their importance lies in their ability to process and generate human-like language quickly, which enables applications to respond rapidly and accurately.\n"
     ]
    }
   ],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of fast language models\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3-8b-8192\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T20:05:40.521792100Z",
     "start_time": "2024-05-13T20:05:39.178881Z"
    }
   },
   "id": "daff60fa63bf76c5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# QA synthetic generation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d17d49cd2f7f6a73"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "QA_generation_prompt = \"\"\"\n",
    "Your task is to write a factoid question and an answer given a context.\n",
    "Your factoid question should be answerable with a specific, concise piece of factual information from the context.\n",
    "Your factoid question should be formulated in the same style as questions users could ask in a search engine.\n",
    "This means that your factoid question MUST NOT mention something like \"according to the passage\" or \"context\".\n",
    "\n",
    "Provide your answer as follows:\n",
    "\n",
    "Output:::\n",
    "Factoid question: (your factoid question)\n",
    "Answer: (your answer to the factoid question)\n",
    "\n",
    "Now here is the context.\n",
    "\n",
    "Context: {context}\\n\n",
    "Output:::\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T20:07:14.303117300Z",
     "start_time": "2024-05-13T20:07:14.286704600Z"
    }
   },
   "id": "2e82f8fcd78f5c3d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# get the docs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1d76cdac755d69f"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading readme:   0%|          | 0.00/21.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5d77e6dd8fe64057b887173e0d6b1cde"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading data:   0%|          | 0.00/22.0M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5846e751cdfc4a23be2bb11b5bfc9f88"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating train split:   0%|          | 0/2647 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f6702eaac60d4f368c5944127ce71fe3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"m-ric/huggingface_doc\", split=\"train\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T20:09:28.564260300Z",
     "start_time": "2024-05-13T20:08:57.834918100Z"
    }
   },
   "id": "8758be240c367375"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['text', 'source'],\n    num_rows: 1\n})"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.take(1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T20:11:48.664012600Z",
     "start_time": "2024-05-13T20:11:48.616000700Z"
    }
   },
   "id": "707b246f3e6eca57"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class Document(Serializable):\n",
      "    \"\"\"Class for storing a piece of text and associated metadata.\"\"\"\n",
      "\n",
      "    page_content: str\n",
      "    \"\"\"String text.\"\"\"\n",
      "    metadata: dict = Field(default_factory=dict)\n",
      "    \"\"\"Arbitrary metadata about the page content (e.g., source, relationships to other\n",
      "        documents, etc.).\n",
      "    \"\"\"\n",
      "    type: Literal[\"Document\"] = \"Document\"\n",
      "\n",
      "    def __init__(self, page_content: str, **kwargs: Any) -> None:\n",
      "        \"\"\"Pass page_content in as positional or named arg.\"\"\"\n",
      "        super().__init__(page_content=page_content, **kwargs)\n",
      "\n",
      "    @classmethod\n",
      "    def is_lc_serializable(cls) -> bool:\n",
      "        \"\"\"Return whether this class is serializable.\"\"\"\n",
      "        return True\n",
      "\n",
      "    @classmethod\n",
      "    def get_lc_namespace(cls) -> List[str]:\n",
      "        \"\"\"Get the namespace of the langchain object.\"\"\"\n",
      "        return [\"langchain\", \"schema\", \"document\"]\n"
     ]
    }
   ],
   "source": [
    "from langchain.docstore.document import Document\n",
    "import inspect\n",
    "\n",
    "\n",
    "print(\n",
    "    \n",
    "    inspect.getsource(\n",
    "        Document\n",
    "    )\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T20:11:20.400607900Z",
     "start_time": "2024-05-13T20:11:20.345415800Z"
    }
   },
   "id": "173e66217190a700"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "_source = ds.take(1)['source']\n",
    "_text = ds.take(1)['text']\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T20:12:20.299361200Z",
     "start_time": "2024-05-13T20:12:20.255477800Z"
    }
   },
   "id": "5694da64092b9a9"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2647/2647 [00:00<00:00, 11119.95it/s]\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document as LangchainDocument\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "langchain_docs = [LangchainDocument(page_content=doc[\"text\"], metadata={\"source\": doc[\"source\"]}) for doc in tqdm(ds)]\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2000,\n",
    "    chunk_overlap=200,\n",
    "    add_start_index=True,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"],\n",
    ")\n",
    "\n",
    "docs_processed = []\n",
    "for doc in langchain_docs:\n",
    "    docs_processed += text_splitter.split_documents([doc])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T20:12:34.791203100Z",
     "start_time": "2024-05-13T20:12:33.397620Z"
    }
   },
   "id": "a72efa2984cadb73"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "13841"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs_processed)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T20:13:27.790560100Z",
     "start_time": "2024-05-13T20:13:27.755948200Z"
    }
   },
   "id": "5ffed0ce4b13ebf6"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['page_content', 'metadata', 'type'])"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_processed[0].__dict__.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T20:15:40.608371900Z",
     "start_time": "2024-05-13T20:15:40.571465100Z"
    }
   },
   "id": "32a1b5a047b4bad"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "35ba176c34aa47d1"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.40it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "_pairs = []\n",
    "for k in tqdm(\n",
    "    random.sample(\n",
    "        docs_processed,\n",
    "        10\n",
    "    )\n",
    "):\n",
    "    page_content = k.page_content\n",
    "    metadata = k.metadata\n",
    "    _prompt = QA_generation_prompt.format(context=page_content)\n",
    "    qa_pair = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": _prompt,\n",
    "            }\n",
    "        ],\n",
    "        model=\"llama3-8b-8192\",\n",
    "    )\n",
    "    \n",
    "    _gen_text = qa_pair.choices[0].message.content\n",
    "    \n",
    "    quesion = _gen_text.split(\"Factoid question:\")[1].split(\"Answer:\")[0].strip()\n",
    "    answer = _gen_text.split(\"Answer:\")[1].strip()\n",
    "    _pairs.append(\n",
    "        {\n",
    "            \"question\": quesion,\n",
    "            \"answer\": answer,\n",
    "            \"context\": page_content,\n",
    "            \"metadata\": metadata['source']\n",
    "        }\n",
    "    )\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T20:23:18.146366400Z",
     "start_time": "2024-05-13T20:23:10.977245900Z"
    }
   },
   "id": "ebd7ed06709292c"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "{'source': 'huggingface/huggingface_hub/blob/main/docs/source/en/guides/manage-cache.md',\n 'start_index': 0}"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T20:22:49.162375700Z",
     "start_time": "2024-05-13T20:22:49.068972700Z"
    }
   },
   "id": "5ef54d3ec105a404"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "{'choices': [{'finish_reason': 'stop',\n   'index': 0,\n   'logprobs': None,\n   'message': {'content': 'Here is the factoid question and answer:\\n\\nFactoid question: What are the types of folders that all caching directories contain?\\nAnswer: refs, blobs, snapshots',\n    'role': 'assistant',\n    'tool_calls': None}}],\n 'id': 'chatcmpl-5d6cc272-7ec1-466d-af68-8647ec0ddf37',\n 'created': 1715631463,\n 'model': 'llama3-8b-8192',\n 'object': 'chat.completion',\n 'system_fingerprint': 'fp_af05557ca2',\n 'usage': {'completion_time': 0.039,\n  'completion_tokens': 32,\n  'prompt_time': 0.141,\n  'prompt_tokens': 571,\n  'queue_time': None,\n  'total_time': 0.18,\n  'total_tokens': 603},\n 'x_groq': {'id': 'req_01hxssn6cef4297j1h802bt7wg'}}"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_pair.dict()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T20:18:39.286580400Z",
     "start_time": "2024-05-13T20:18:39.268634900Z"
    }
   },
   "id": "9e56411f3bc694fb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# write the generated QA to yaml\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ddce562f74420cd"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "import yaml\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "with open(\"data/qa_pairs.yaml\", \"w\") as f:\n",
    "    yaml.dump(_pairs, f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T20:24:28.351173900Z",
     "start_time": "2024-05-13T20:24:28.291592800Z"
    }
   },
   "id": "cebf5300d51b7968"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "                                            question  \\\n0  What are some ideas of areas where I can contr...   \n1  What is the top 1 accuracy of the model on the...   \n2  What is the task set when initializing the `In...   \n3          What is the model size of SetFit Roberta?   \n4         What is the theme used in the Gradio demo?   \n5  Who fixed the issue mentioned in pull request ...   \n6  What is an available pipeline for multimodal t...   \n7  How can you upload an Argilla dataset programm...   \n8      What has rinna Co., Ltd. released models for?   \n9  What layers should be added to `modules_to_sav...   \n\n                                              answer  \\\n0  Share exciting models with the community throu...   \n1                                             80.25%   \n2                                 feature-extraction   \n3                                        355 million   \n4                                               Base   \n5                                           abidlabs   \n6                                ImageToTextPipeline   \n7                  Using the argilla Python library.   \n8                                     Japanese text.   \n9  Newly initialized layers mentioned in a warnin...   \n\n                                             context  \\\n0  * **Where and how can I contribute?**\\n  \\nIt ...   \n1  Weights: https://github.com/rwightman/pytorch-...   \n2  Some tasks might also require additional param...   \n3  And just by switching out the base Sentence Tr...   \n4  Gradio Demo: diff_texts\\n\\n\\n```\\n!pip install...   \n5  - [#6680](https://github.com/gradio-app/gradio...   \n6  [[autodoc]] VideoClassificationPipeline\\n    -...   \n7  <div class=\"flex justify-center\">\\n<img src=\"h...   \n8  ## What’s Next?\\nCompared to Stable Diffusion,...   \n9  In PEFT, we try to correctly guess the `module...   \n\n                                            metadata  \n0           huggingface/blog/blob/main/fellowship.md  \n1  huggingface/pytorch-image-models/blob/main/hfd...  \n2  huggingface/huggingface_hub/blob/main/src/hugg...  \n3               huggingface/blog/blob/main/setfit.md  \n4  gradio-app/gradio/blob/main/demo/diff_texts/ru...  \n5           gradio-app/gradio/blob/main/CHANGELOG.md  \n6  huggingface/transformers/blob/main/docs/source...  \n7  huggingface/hub-docs/blob/main/docs/hub/spaces...  \n8  huggingface/blog/blob/main/japanese-stable-dif...  \n9  huggingface/peft/blob/main/docs/source/develop...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>answer</th>\n      <th>context</th>\n      <th>metadata</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What are some ideas of areas where I can contr...</td>\n      <td>Share exciting models with the community throu...</td>\n      <td>* **Where and how can I contribute?**\\n  \\nIt ...</td>\n      <td>huggingface/blog/blob/main/fellowship.md</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>What is the top 1 accuracy of the model on the...</td>\n      <td>80.25%</td>\n      <td>Weights: https://github.com/rwightman/pytorch-...</td>\n      <td>huggingface/pytorch-image-models/blob/main/hfd...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>What is the task set when initializing the `In...</td>\n      <td>feature-extraction</td>\n      <td>Some tasks might also require additional param...</td>\n      <td>huggingface/huggingface_hub/blob/main/src/hugg...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>What is the model size of SetFit Roberta?</td>\n      <td>355 million</td>\n      <td>And just by switching out the base Sentence Tr...</td>\n      <td>huggingface/blog/blob/main/setfit.md</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>What is the theme used in the Gradio demo?</td>\n      <td>Base</td>\n      <td>Gradio Demo: diff_texts\\n\\n\\n```\\n!pip install...</td>\n      <td>gradio-app/gradio/blob/main/demo/diff_texts/ru...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Who fixed the issue mentioned in pull request ...</td>\n      <td>abidlabs</td>\n      <td>- [#6680](https://github.com/gradio-app/gradio...</td>\n      <td>gradio-app/gradio/blob/main/CHANGELOG.md</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>What is an available pipeline for multimodal t...</td>\n      <td>ImageToTextPipeline</td>\n      <td>[[autodoc]] VideoClassificationPipeline\\n    -...</td>\n      <td>huggingface/transformers/blob/main/docs/source...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>How can you upload an Argilla dataset programm...</td>\n      <td>Using the argilla Python library.</td>\n      <td>&lt;div class=\"flex justify-center\"&gt;\\n&lt;img src=\"h...</td>\n      <td>huggingface/hub-docs/blob/main/docs/hub/spaces...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>What has rinna Co., Ltd. released models for?</td>\n      <td>Japanese text.</td>\n      <td>## What’s Next?\\nCompared to Stable Diffusion,...</td>\n      <td>huggingface/blog/blob/main/japanese-stable-dif...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>What layers should be added to `modules_to_sav...</td>\n      <td>Newly initialized layers mentioned in a warnin...</td>\n      <td>In PEFT, we try to correctly guess the `module...</td>\n      <td>huggingface/peft/blob/main/docs/source/develop...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "pd.DataFrame.from_dict(_pairs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T20:27:55.104426400Z",
     "start_time": "2024-05-13T20:27:55.006261Z"
    }
   },
   "id": "25d4c3fda566daa5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f2ba65143b5a8386"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
